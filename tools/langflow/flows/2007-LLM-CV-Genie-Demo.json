{
  "updated_at": "2025-08-13T23:23:39+00:00",
  "user_id": "74d0975a-b275-4425-98b6-f0aadd4ec950",
  "icon_bg_color": null,
  "icon": null,
  "name": "LLM CV Demo",
  "description": "Full Demo for WoS",
  "webhook": false,
  "endpoint_name": null,
  "tags": null,
  "folder_id": "b8c180b2-0f3a-4c2c-8f5b-e97adb17e0ce",
  "gradient": null,
  "id": "5585376c-e2d3-4769-b791-5c57303cdb4a",
  "is_component": false,
  "data": {
    "nodes": [
      {
        "id": "ChatInput-KDKV4",
        "type": "genericNode",
        "position": {
          "x": -352.3647411625032,
          "y": -98.80871123761433
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import os\r\nfrom langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\r\nfrom langflow.base.io.chat import ChatComponent\r\nfrom langflow.inputs import BoolInput\r\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\r\nfrom langflow.schema.message import Message\r\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_USER, MESSAGE_SENDER_USER\r\n\r\n\r\nclass ChatInput(ChatComponent):\r\n    display_name = \"Chat Input\"\r\n    description = \"Get chat inputs from the Playground.\"\r\n    icon = \"MessagesSquare\"\r\n    name = \"ChatInput\"\r\n\r\n    inputs = [\r\n        MultilineInput(\r\n            name=\"input_value\",\r\n            display_name=\"Text\",\r\n            value=\"\",\r\n            info=\"Message to be passed as input.\",\r\n        ),\r\n        BoolInput(\r\n            name=\"should_store_message\",\r\n            display_name=\"Store Messages\",\r\n            info=\"Store the message in the history.\",\r\n            value=True,\r\n            advanced=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"sender\",\r\n            display_name=\"Sender Type\",\r\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\r\n            value=MESSAGE_SENDER_USER,\r\n            info=\"Type of sender.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"sender_name\",\r\n            display_name=\"Sender Name\",\r\n            info=\"Name of the sender.\",\r\n            value=MESSAGE_SENDER_NAME_USER,\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"session_id\",\r\n            display_name=\"Session ID\",\r\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\r\n            advanced=True,\r\n        ),\r\n        FileInput(\r\n            name=\"files\",\r\n            display_name=\"Files\",\r\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\r\n            info=\"Files to be sent with the message.\",\r\n            advanced=True,\r\n            is_list=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"background_color\",\r\n            display_name=\"Background Color\",\r\n            info=\"The background color of the icon.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"chat_icon\",\r\n            display_name=\"Icon\",\r\n            info=\"The icon of the message.\",\r\n            advanced=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"text_color\",\r\n            display_name=\"Text Color\",\r\n            info=\"The text color of the name\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\r\n    ]\r\n    \r\n    def set_file_path(self, file_path):\r\n        if type(file_path) is list:\r\n            for fp in file_path:\r\n                return os.path.normpath(str(fp)).replace(os.sep, \"/\")\r\n        if type(file_path) is str:\r\n            return os.path.normpath(str(file_path)).replace(os.sep, \"/\")\r\n\r\n    def message_response(self) -> Message:\r\n        _background_color = self.background_color\r\n        _text_color = self.text_color\r\n        _icon = self.chat_icon\r\n        files_path = self.set_file_path(self.files)\r\n        message = Message(\r\n            text=self.input_value,\r\n            sender=self.sender,\r\n            sender_name=self.sender_name,\r\n            session_id=self.session_id,\r\n            files=files_path,\r\n            properties={\"background_color\": _background_color, \"text_color\": _text_color, \"icon\": _icon},\r\n        )\r\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\r\n            stored_message = self.send_message(\r\n                message,\r\n            )\r\n            self.message.value = stored_message\r\n            message = stored_message\r\n\r\n        self.status = message\r\n        return message\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "hi",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatInput",
          "id": "ChatInput-KDKV4"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": -352.3647411625032,
          "y": -98.80871123761433
        },
        "dragging": false
      },
      {
        "id": "Prompt-9opmi",
        "type": "genericNode",
        "position": {
          "x": -240.8332826939585,
          "y": -555.0442645387345
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "### Instruction:\nBased on the user's prompt, determine if any of the following image operation are required: Image Classification, Object Detection, Pose Estimation, Super Resolution, Semantic Segmentation.  The super resolution is same as improve the image or increate the resolution of the image . If the user's prompt requires any of actions, output the action name.  Otherwise, output \"No operation action need\".\n\n### Tools:\n1. Image Classification\n2. Object Detection\n3. Pose Estimation\n4. Super Resolution\n5. Semantic Segmentation\n\n### Examples:\n#### Example 1:\n### User Prompt:\n\"Classify this image\"\n### Output:\nImage Classification\n\n#### Example 2:\n### User Prompt:\n\"Classify the type of animal in this picture.\"\n### Output:\nImage Classification\n\n#### Example 3:\n### User Prompt:\n\"Can you identify the objects in this image?\"\n### Output:\nObject Detection\n\n#### Example 4:\n### User Prompt:\n\"Detect the object in this image \"\n### Output:\nObject Detection\n\n### Example 5:\n### User Prompt:\n\"Find the different objects in this picture.\"\n### Output:\nObject Detection\n\n\n#### Example 6:\n### User Prompt:\n\"What's the pose of the person in this photo?\"\n### Output:\nPose Estimation\n\n### Example 7:\n### User Prompt:\n\"What's the position of the person in this image?\"\n### Output:\nPose Estimation\n\n#### Example 8:\n### User Prompt:\n\"Please super resolution this image.\"\n### Output:\nSuper Resolution\n\n#### Example 9:\n### User Prompt:\n\"Please enhance the resolution of this image\"\n### Output:\nSuper Resolution\n\n#### Example 10:\n### User Prompt:\n\"Improve the image quality\"\n### Output:\nSuper Resolution\n\n#### Example 11:\n### User Prompt:\n\"Segment the different regions in this image.\"\n### Output:\nSemantic Segmentation.\n\n### Example 12:\n### User Prompt:\n\"Divide this image into its different parts.\"\n### Output:\nSemantic Segmentation.\n\n#### Example 13:\n### User Prompt:\n\"Tell me a joke.\"\n### Output:\nNo operation action need.\n### Example 14:\n### User Prompt:\n\"What's the weather like today?\"\n### Output:\nNo operation action need\n### User Prompt:\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": []
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Prompt",
          "id": "Prompt-9opmi"
        },
        "selected": false,
        "width": 320,
        "height": 259,
        "positionAbsolute": {
          "x": -240.8332826939585,
          "y": -555.0442645387345
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-qr1bp",
        "type": "genericNode",
        "position": {
          "x": 404.1773483748191,
          "y": -484.56675083834944
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=['Qwen2.0-7B-SSD'],\n            value='Qwen2.0-7B-SSD',\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Qwen2.0-7B-SSD"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "Qwen2.0-7B-SSD",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "http://127.0.0.1:8910/v1",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false
          },
          "type": "OpenAIModel",
          "id": "OpenAIModel-qr1bp"
        },
        "selected": false,
        "width": 320,
        "height": 672,
        "positionAbsolute": {
          "x": 404.1773483748191,
          "y": -484.56675083834944
        },
        "dragging": false
      },
      {
        "id": "ConditionalRouter-awkKa",
        "type": "genericNode",
        "position": {
          "x": 883.3366272216033,
          "y": 343.33109345201206
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\n\n\nclass ConditionalRouterComponent(Component):\n    display_name = \"Qualcomm Langflow Switch\"\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\n    icon = \"split\"\n    name = \"ConditionalRouter\"\n\n    def check_action(self, input_text, match_action):\n        if match_action in input_text :\n            print(f'{input_text} : {match_action} return True')\n            return True\n        else:\n            print(f'{input_text} : {match_action} return False')\n            return False \n            \n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.__iteration_updated = False\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_text\",\n            display_name=\"Text Input\",\n            info=\"The primary text input for the operation.\",\n        ),\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The message to pass through either route.\",\n            advanced=True,\n        ),\n\n    ]\n\n    outputs = [\n        Output(display_name=\"Image Classification\", name=\"image_classification_result\", method=\"image_classification_response\"),\n        Output(display_name=\"Object Detection\", name=\"object_detection_result\", method=\"object_detection_response\"),\n        Output(display_name=\"Pose Estimation\", name=\"pose_estimation_result\", method=\"pose_estimation_response\"),\n        Output(display_name=\"Super Resolution\", name=\"super_resolution_result\", method=\"super_resolution_response\"),\n        Output(display_name=\"Semantic Segmentation\", name=\"semantic_segmentation_result\", method=\"semantic_segmentation_response\"),\n        Output(display_name=\"Other\", name=\"other_result\", method=\"other_response\"),\n\n    ]\n\n    def iterate_and_stop_once(self, route_to_stop: str):\n            self.stop(route_to_stop)\n\n    def image_classification_response(self) -> Message:\n        self.message.text = self.input_text\n        self.input_text_string=\"\".join(self.input_text)\n        if self.check_action(self.input_text_string,\"Image Classification\"):\n            #self.iterate_and_stop_once(\"image_classification_result\")\n            self.iterate_and_stop_once(\"object_detection_result\")\n            self.iterate_and_stop_once(\"pose_estimation_result\")\n            self.iterate_and_stop_once(\"super_resolution_result\")\n            self.iterate_and_stop_once(\"semantic_segmentation_result\")\n            self.iterate_and_stop_once(\"other_result\")\n        else:\n            self.iterate_and_stop_once(\"image_classification_result\")\n            \n        return self.message\n\n\n\n    def object_detection_response(self) -> Message:\n        self.message.text = self.input_text\n        self.input_text_string=\"\".join(self.input_text)\n        if self.check_action(self.input_text_string,\"Object Detection\"):\n            self.iterate_and_stop_once(\"image_classification_result\")\n            #self.iterate_and_stop_once(\"object_detection_result\")\n            self.iterate_and_stop_once(\"pose_estimation_result\")\n            self.iterate_and_stop_once(\"super_resolution_result\")\n            self.iterate_and_stop_once(\"semantic_segmentation_result\")\n            self.iterate_and_stop_once(\"other_result\")\n        else:\n            self.iterate_and_stop_once(\"object_detection_result\")\n        return self.message\n\n    def pose_estimation_response(self) -> Message:\n        self.message.text = self.input_text\n        self.input_text_string=\"\".join(self.input_text)\n        if self.check_action(self.input_text_string,\"Pose Estimation\"):\n            self.iterate_and_stop_once(\"image_classification_result\")\n            self.iterate_and_stop_once(\"object_detection_result\")\n            #self.iterate_and_stop_once(\"pose_estimation_result\")\n            self.iterate_and_stop_once(\"super_resolution_result\")\n            self.iterate_and_stop_once(\"semantic_segmentation_result\")\n            self.iterate_and_stop_once(\"other_result\")\n        else:\n            self.iterate_and_stop_once(\"pose_estimation_result\")\n        return self.message\n\n    def super_resolution_response(self) -> Message:\n        self.message.text = self.input_text\n        self.input_text_string=\"\".join(self.input_text)\n        if self.check_action(self.input_text_string,\"Super Resolution\"):\n            self.iterate_and_stop_once(\"image_classification_result\")\n            self.iterate_and_stop_once(\"object_detection_result\")\n            self.iterate_and_stop_once(\"pose_estimation_result\")\n            #self.iterate_and_stop_once(\"super_resolution_result\")\n            self.iterate_and_stop_once(\"semantic_segmentation_result\")\n            self.iterate_and_stop_once(\"other_result\")\n        else:\n            self.iterate_and_stop_once(\"super_resolution_result\")\n        return self.message\n\n    def semantic_segmentation_response(self) -> Message:\n        self.message.text = self.input_text\n        self.input_text_string=\"\".join(self.input_text)\n        if self.check_action(self.input_text_string,\"Semantic Segmentation\"):\n            self.iterate_and_stop_once(\"image_classification_result\")\n            self.iterate_and_stop_once(\"object_detection_result\")\n            self.iterate_and_stop_once(\"pose_estimation_result\")\n            self.iterate_and_stop_once(\"super_resolution_result\")\n            #self.iterate_and_stop_once(\"semantic_segmentation_result\")\n            self.iterate_and_stop_once(\"other_result\")\n        else:\n            self.iterate_and_stop_once(\"semantic_segmentation_result\")\n            \n        return self.message\n\n        \n        \n    def other_response(self) -> Message:\n        \n        self.message.text = self.input_text\n        self.input_text_string=\"\".join(self.input_text)\n        \n        actions=[\"Image Classification\",\"Object Detection\",\"Pose Estimation\",\"Super Resolution\",\"Semantic Segmentation\"]\n        results = [ self.check_action(self.input_text_string,action) for action in actions]\n        all_false=all(result == False for result in results)\n        \n        # Check if none of the substrings are in the text\n        if all_false:\n            self.iterate_and_stop_once(\"image_classification_result\")\n            self.iterate_and_stop_once(\"object_detection_result\")\n            self.iterate_and_stop_once(\"pose_estimation_result\")\n            self.iterate_and_stop_once(\"super_resolution_result\")\n            self.iterate_and_stop_once(\"semantic_segmentation_result\")\n            #self.iterate_and_stop_once(\"other_result\")\n\n        else:\n            self.iterate_and_stop_once(\"other_result\")\n            \n        \n        return self.message\n\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_text": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_text",
                "value": "",
                "display_name": "Text Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The message to pass through either route.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "icon": "split",
            "base_classes": [
              "Message"
            ],
            "display_name": "Langflow CV Switch",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "image_classification_result",
                "display_name": "Image Classification",
                "method": "image_classification_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "object_detection_result",
                "display_name": "Object Detection",
                "method": "object_detection_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "pose_estimation_result",
                "display_name": "Pose Estimation",
                "method": "pose_estimation_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "super_resolution_result",
                "display_name": "Super Resolution",
                "method": "super_resolution_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "semantic_segmentation_result",
                "display_name": "Semantic Segmentation",
                "method": "semantic_segmentation_response",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "other_result",
                "display_name": "Other",
                "method": "other_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_text",
              "message"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ConditionalRouter",
          "id": "ConditionalRouter-awkKa"
        },
        "selected": false,
        "width": 320,
        "height": 493,
        "positionAbsolute": {
          "x": 883.3366272216033,
          "y": 343.33109345201206
        },
        "dragging": false
      },
      {
        "id": "TextInput-qUoeY",
        "type": "genericNode",
        "position": {
          "x": 840.9263220064074,
          "y": -464.84177795081
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "file_1": {
                "trace_as_metadata": true,
                "file_path": "5585376c-e2d3-4769-b791-5c57303cdb4a\\2025-08-14_06-41-48_real_esrgan_x4plus.jpg",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "file_1",
                "value": "",
                "display_name": "File 1",
                "advanced": false,
                "dynamic": false,
                "info": "File 1 to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput",
                "load_from_db": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom PIL import Image\n\nclass QualcommCVInput(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n    MAX_FILES = 1 \n    inputs = [\n        \n    ]\n    \n    \n        # Dynamically add multiple FileInput fields\n    for i in range(1, MAX_FILES + 1):\n        inputs.append(\n            FileInput(\n                name=f\"file_{i}\",\n                display_name=f\"File {i}\",\n                file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n                info=f\"File {i} to be sent with the message.\",\n                advanced=False,\n                is_list=False,  # Each FileInput handles a single file\n            )\n        )\n\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"message_response\"),\n    ]\n\n\n    def message_response(self) -> Message:\n        # Collect all uploaded files into a list\n        files = []\n        files_path=[]\n        for i in range(1, self.MAX_FILES + 1):\n            file = getattr(self, f\"file_{i}\", None)\n            if file:\n                \n                files.append(file)\n\n                resolved_path = self.resolve_path(file)\n                files_path.append(resolved_path)\n                # Open and read the image file\n                \n                image = Image.open(resolved_path)\n                \n                width, height = image.size\n                \n                print(f\"resolved_path: {resolved_path} , Width: {width}, Height: {height}\")\n                image.close()\n\n\n\n        message = Message(text=\"Qualcomm CV\", sender=MESSAGE_SENDER_USER, files=files_path)\n        # Update the component status\n        self.status = message\n        return message",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Qualcomm CV Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "file_1"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "TextInput",
          "id": "TextInput-qUoeY"
        },
        "selected": false,
        "width": 320,
        "height": 231,
        "positionAbsolute": {
          "x": 840.9263220064074,
          "y": -464.84177795081
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-RVEjl",
        "type": "genericNode",
        "position": {
          "x": 1961.8737148283185,
          "y": -600.4766690716551
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "outputs",
            "key": "ChatOutput",
            "score": 0.00012027401062119145,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-RVEjl"
        },
        "selected": false,
        "width": 320,
        "height": 185,
        "positionAbsolute": {
          "x": 1961.8737148283185,
          "y": -600.4766690716551
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-GePEK",
        "type": "genericNode",
        "position": {
          "x": 1954.2380865510595,
          "y": 1736.5337596249371
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "outputs",
            "key": "ChatOutput",
            "score": 0.00012027401062119145,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-GePEK"
        },
        "selected": false,
        "width": 320,
        "height": 185,
        "positionAbsolute": {
          "x": 1954.2380865510595,
          "y": 1736.5337596249371
        },
        "dragging": false
      },
      {
        "id": "Pass-WCW5M",
        "type": "genericNode",
        "position": {
          "x": 930.6683070219522,
          "y": 1080.8361599992459
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.io import MessageInput\nfrom langflow.schema.message import Message\nfrom langflow.template import Output\n\n\nclass PassMessageComponent(Component):\n    display_name = \"Pass\"\n    description = \"Forwards the input message, unchanged.\"\n    name = \"Pass\"\n    icon = \"arrow-right\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_message\",\n            display_name=\"Input Message\",\n            info=\"The message to be passed forward.\",\n        ),\n        MessageInput(\n            name=\"ignored_message\",\n            display_name=\"Ignored Message\",\n            info=\"A second message to be ignored. Used as a workaround for continuity.\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output Message\", name=\"output_message\", method=\"pass_message\"),\n    ]\n\n    def pass_message(self) -> Message:\n        self.status = self.input_message\n        return self.input_message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "ignored_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "ignored_message",
                "value": "",
                "display_name": "Ignored Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A second message to be ignored. Used as a workaround for continuity.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "input_message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_message",
                "value": "",
                "display_name": "Input Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The message to be passed forward.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Forwards the input message, unchanged.",
            "icon": "arrow-right",
            "base_classes": [
              "Message"
            ],
            "display_name": "Pass",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output_message",
                "display_name": "Output Message",
                "method": "pass_message",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_message",
              "ignored_message"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Pass",
          "id": "Pass-WCW5M"
        },
        "selected": false,
        "width": 320,
        "height": 320,
        "positionAbsolute": {
          "x": 930.6683070219522,
          "y": 1080.8361599992459
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-CuNHs",
        "type": "genericNode",
        "position": {
          "x": 1418.4917666956921,
          "y": 772.3987160564618
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.schema.content_block import ContentBlock\nfrom langflow.schema.content_types import TextContent, MediaContent\nimport socket\nimport sys\nimport subprocess\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"code\"\n    name = \"CustomComponent\"\n\n    inputs = [\n                MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The Message object from ChatInput\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n    \n    def get_host_ip(self):\n        host_name=socket.gethostname()\n        ip_addr=socket.gethostbyname(host_name)\n        return ip_addr  \n\n    def build_output(self) -> Message:\n\n\n\n\n        image_path_list=[]\n        \n        \n        for file in self.message.files:\n            image_path=str(file.path)\n            image_path_list.append(image_path)\n            \n        print(f'image_path_list: {image_path_list}')\n    \n        original_cwd = os.getcwd()\n        \n\n        # Extract the file name and directory\n        directory, filename = os.path.split(image_path)\n        name, ext = os.path.splitext(filename)\n        output_filename = f\"{name}_yolov8_output.png\"\n        \n        # Create new file name\n        output_image_path = os.path.join(directory, output_filename)\n\n\n\n        user_folder_path = os.environ['USERPROFILE']\n        ai_helper_sample_path = os.path.join(original_cwd, '..\\\\ai-engine-direct-helper\\\\samples\\\\')\n        os.chdir(ai_helper_sample_path)\n        sys.path.append(ai_helper_sample_path)\n        from python.unet_segmentation.unet_segmentation import main as unet_main\n        #image_path=None,mask_path=None,output_path=None\n        result=unet_main(image_path=image_path_list[0],output_path=output_image_path,show_image=False)            \n        #result='Hello'\n        print(f'{result}')\n        result_list=[]\n        result_list.append(result)\n        sys.path.remove(ai_helper_sample_path)\n\n    \n        os.chdir(original_cwd)\n\n\n\n    \n        url_list=[]\n        for each_item in image_path_list:\n            directory, filename = os.path.split(each_item)\n            url_list.append(f'http://{self.get_host_ip()}:8979/api/v1/files/images/{self.graph.flow_id}/{filename}')\n\n\n        output_url=f'http://{self.get_host_ip()}:8979/api/v1/files/images/{self.graph.flow_id}/{output_filename}'\n\n        \n        print(f'url_list: {url_list}')\n        content_blocks=[]\n        \n        for url,infer_result in zip(url_list,result_list):\n            \n            content_blocks.append(\n                ContentBlock(\n                title=\"Input Image\",\n                contents=[\n                MediaContent(type=\"media\", urls=[url,output_url])\n                ]\n                )\n            )\n            \n            content_blocks.append(\n                ContentBlock(\n                    title=\"Inference result\",\n                    contents=[\n                    TextContent(type=\"text\", text=infer_result)\n                    ]\n                )\n            )\n\n        message = Message(\n            text=\"This Unet Segmentation result\",\n            sender=\"User\",\n            sender_name=\"Qualcomm AI\",\n            content_blocks=content_blocks\n        )\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Message object from ChatInput",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Use as a template to create your own component.",
            "icon": "code",
            "base_classes": [
              "Message"
            ],
            "display_name": "UNet Segmentation",
            "documentation": "http://docs.langflow.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "message"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-CuNHs"
        },
        "selected": false,
        "width": 320,
        "height": 340,
        "positionAbsolute": {
          "x": 1418.4917666956921,
          "y": 772.3987160564618
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-P24jk",
        "type": "genericNode",
        "position": {
          "x": 1948.410196551009,
          "y": 943.0085997479962
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "outputs",
            "key": "ChatOutput",
            "score": 0.00012027401062119145,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-P24jk"
        },
        "selected": false,
        "width": 320,
        "height": 185,
        "positionAbsolute": {
          "x": 1948.410196551009,
          "y": 943.0085997479962
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-tNBEY",
        "type": "genericNode",
        "position": {
          "x": 1402.6242476140885,
          "y": 21.55144944220052
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.schema.content_block import ContentBlock\nfrom langflow.schema.content_types import TextContent, MediaContent\nimport socket\nimport sys\nimport subprocess\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"code\"\n    name = \"CustomComponent\"\n\n    inputs = [\n                MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The Message object from ChatInput\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n    \n    def get_host_ip(self):\n        host_name=socket.gethostname()\n        ip_addr=socket.gethostbyname(host_name)\n        return ip_addr  \n\n    def build_output(self) -> Message:\n\n\n\n\n        image_path_list=[]\n        \n        \n        for file in self.message.files:\n            image_path=str(file.path)\n            image_path_list.append(image_path)\n            \n        print(f'image_path_list: {image_path_list}')\n    \n        original_cwd = os.getcwd()\n        \n\n        # Extract the file name and directory\n        directory, filename = os.path.split(image_path)\n        name, ext = os.path.splitext(filename)\n        output_filename = f\"{name}_open_pose_output.png\"\n        \n        # Create new file name\n        output_image_path = os.path.join(directory, output_filename)\n\n\n\n        user_folder_path = os.environ['USERPROFILE']\n        ai_helper_sample_path = os.path.join(original_cwd, '..\\\\ai-engine-direct-helper\\\\samples\\\\')\n        print(ai_helper_sample_path)\n        os.chdir(ai_helper_sample_path)\n        sys.path.append(ai_helper_sample_path)\n        from python.openpose.openpose import main as openpose_main\n        #image_path=None,mask_path=None,output_path=None\n        result=openpose_main(input_image_path=image_path_list[0],output_image_path=output_image_path,show_image=False)            \n        #result='Hello'\n        print(f'{result}')\n        result_list=[]\n        result_list.append(result)\n        sys.path.remove(ai_helper_sample_path)\n\n    \n        os.chdir(original_cwd)\n\n\n\n    \n        url_list=[]\n        for each_item in image_path_list:\n            directory, filename = os.path.split(each_item)\n            url_list.append(f'http://{self.get_host_ip()}:8979/api/v1/files/images/{self.graph.flow_id}/{filename}')\n\n\n        output_url=f'http://{self.get_host_ip()}:8979/api/v1/files/images/{self.graph.flow_id}/{output_filename}'\n\n        \n        print(f'url_list: {url_list}')\n        content_blocks=[]\n        \n        for url,infer_result in zip(url_list,result_list):\n            \n            content_blocks.append(\n                ContentBlock(\n                title=\"Input Image\",\n                contents=[\n                MediaContent(type=\"media\", urls=[url,output_url])\n                ]\n                )\n            )\n            \n            content_blocks.append(\n                ContentBlock(\n                    title=\"Inference result\",\n                    contents=[\n                    TextContent(type=\"text\", text=infer_result)\n                    ]\n                )\n            )\n\n        message = Message(\n            text=\"This is the OpenPose inference  result\",\n            sender=\"User\",\n            sender_name=\"Qualcomm AI\",\n            content_blocks=content_blocks\n        )\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Message object from ChatInput",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Use as a template to create your own component.",
            "icon": "code",
            "base_classes": [
              "Message"
            ],
            "display_name": "Open Pose",
            "documentation": "http://docs.langflow.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "message"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-tNBEY"
        },
        "selected": false,
        "width": 320,
        "height": 340,
        "positionAbsolute": {
          "x": 1402.6242476140885,
          "y": 21.55144944220052
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-qHo0x",
        "type": "genericNode",
        "position": {
          "x": 1937.3647461408623,
          "y": 190.77153593093982
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "outputs",
            "key": "ChatOutput",
            "score": 0.00012027401062119145,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-qHo0x"
        },
        "selected": false,
        "width": 320,
        "height": 185,
        "positionAbsolute": {
          "x": 1937.3647461408623,
          "y": 190.77153593093982
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-HPvIk",
        "type": "genericNode",
        "position": {
          "x": 1963.085915021688,
          "y": -215.82029535606486
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "outputs",
            "key": "ChatOutput",
            "score": 0.00012027401062119145,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-HPvIk"
        },
        "selected": false,
        "width": 320,
        "height": 185,
        "positionAbsolute": {
          "x": 1963.085915021688,
          "y": -215.82029535606486
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-bIZHN",
        "type": "genericNode",
        "position": {
          "x": 1422.028154458472,
          "y": 394.98231853414313
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.schema.content_block import ContentBlock\nfrom langflow.schema.content_types import TextContent, MediaContent\nimport socket\nimport sys\nimport subprocess\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"code\"\n    name = \"CustomComponent\"\n\n    inputs = [\n                MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The Message object from ChatInput\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n    \n    def get_host_ip(self):\n        host_name=socket.gethostname()\n        ip_addr=socket.gethostbyname(host_name)\n        return ip_addr  \n\n    def build_output(self) -> Message:\n\n\n\n\n        image_path_list=[]\n        \n        \n        for file in self.message.files:\n            image_path=str(file.path)\n            image_path_list.append(image_path)\n            \n        print(f'image_path_list: {image_path_list}')\n    \n        original_cwd = os.getcwd()\n        \n\n        # Extract the file name and directory\n        directory, filename = os.path.split(image_path)\n        name, ext = os.path.splitext(filename)\n        output_filename = f\"{name}_esr_output.png\"\n        \n        # Create new file name\n        output_image_path = os.path.join(directory, output_filename)\n\n\n\n        user_folder_path = os.environ['USERPROFILE']\n        ai_helper_sample_path = os.path.join(original_cwd, '..\\\\ai-engine-direct-helper\\\\samples\\\\')\n        os.chdir(ai_helper_sample_path)\n        sys.path.append(ai_helper_sample_path)\n        from python.real_esrgan_x4plus.real_esrgan_x4plus import main as real_esrgan_main\n        #image_path=None,mask_path=None,output_path=None\n        result=real_esrgan_main(input_image_path=image_path_list[0],output_image_path=output_image_path,show_image=False)            \n        #result='Hello'\n        print(f'{result}')\n        result_list=[]\n        result_list.append(result)\n        sys.path.remove(ai_helper_sample_path)\n\n    \n        os.chdir(original_cwd)\n\n\n\n    \n        url_list=[]\n        for each_item in image_path_list:\n            directory, filename = os.path.split(each_item)\n            url_list.append(f'http://{self.get_host_ip()}:8979/api/v1/files/images/{self.graph.flow_id}/{filename}')\n\n\n        output_url=f'http://{self.get_host_ip()}:8979/api/v1/files/images/{self.graph.flow_id}/{output_filename}'\n\n        \n        print(f'url_list: {url_list}')\n        content_blocks=[]\n        \n        for url,infer_result in zip(url_list,result_list):\n            \n            content_blocks.append(\n                ContentBlock(\n                title=\"Input Image\",\n                contents=[\n                MediaContent(type=\"media\", urls=[url,output_url])\n                ]\n                )\n            )\n            \n            content_blocks.append(\n                ContentBlock(\n                    title=\"Inference result\",\n                    contents=[\n                    TextContent(type=\"text\", text=infer_result)\n                    ]\n                )\n            )\n\n        message = Message(\n            text=\"This is the Real ESR Gan Inference Result\",\n            sender=\"User\",\n            sender_name=\"Qualcomm AI\",\n            content_blocks=content_blocks\n        )\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Message object from ChatInput",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Use as a template to create your own component.",
            "icon": "code",
            "base_classes": [
              "Message"
            ],
            "display_name": "real_esrgan_x4plus",
            "documentation": "http://docs.langflow.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "message"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-bIZHN"
        },
        "selected": false,
        "width": 320,
        "height": 340,
        "positionAbsolute": {
          "x": 1422.028154458472,
          "y": 394.98231853414313
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-E9zvI",
        "type": "genericNode",
        "position": {
          "x": 1947.595882833457,
          "y": 519.1185202578394
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "outputs",
            "key": "ChatOutput",
            "score": 0.00012027401062119145,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-E9zvI"
        },
        "selected": false,
        "width": 320,
        "height": 185,
        "positionAbsolute": {
          "x": 1947.595882833457,
          "y": 519.1185202578394
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-N6ZzD",
        "type": "genericNode",
        "position": {
          "x": 1403.3913773034235,
          "y": -361.9688197278271
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.schema.content_block import ContentBlock\nfrom langflow.schema.content_types import TextContent, MediaContent\nimport socket\nimport sys\nimport subprocess\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"code\"\n    name = \"CustomComponent\"\n\n    inputs = [\n                MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The Message object from ChatInput\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n    \n    def get_host_ip(self):\n        host_name=socket.gethostname()\n        ip_addr=socket.gethostbyname(host_name)\n        return ip_addr  \n\n    def build_output(self) -> Message:\n\n\n\n\n        image_path_list=[]\n        \n        \n        for file in self.message.files:\n            image_path=str(file.path)\n            image_path_list.append(image_path)\n            \n        print(f'image_path_list: {image_path_list}')\n    \n        original_cwd = os.getcwd()\n        \n\n        # Extract the file name and directory\n        directory, filename = os.path.split(image_path)\n        name, ext = os.path.splitext(filename)\n        output_filename = f\"{name}_yolov8_output.png\"\n        \n        # Create new file name\n        output_image_path = os.path.join(directory, output_filename)\n\n\n\n        user_folder_path = os.environ['USERPROFILE']\n        ai_helper_sample_path = os.path.join(original_cwd, '..\\\\ai-engine-direct-helper\\\\samples\\\\')\n        os.chdir(ai_helper_sample_path)\n        sys.path.append(ai_helper_sample_path)\n        from python.yolov8_det.yolov8_det import main as yolov8_det_main\n        #image_path=None,mask_path=None,output_path=None\n        result=yolov8_det_main(input_image_path=image_path_list[0],output_image_path=output_image_path,show_image=False)            \n        #result='Hello'\n        print(f'{result}')\n        result_list=[]\n        result_list.append(result)\n        sys.path.remove(ai_helper_sample_path)\n\n    \n        os.chdir(original_cwd)\n\n\n\n    \n        url_list=[]\n        for each_item in image_path_list:\n            directory, filename = os.path.split(each_item)\n            url_list.append(f'http://{self.get_host_ip()}:8979/api/v1/files/images/{self.graph.flow_id}/{filename}')\n\n\n        output_url=f'http://{self.get_host_ip()}:8979/api/v1/files/images/{self.graph.flow_id}/{output_filename}'\n\n        \n        print(f'url_list: {url_list}')\n        content_blocks=[]\n        \n        for url,infer_result in zip(url_list,result_list):\n            \n            content_blocks.append(\n                ContentBlock(\n                title=\"Input Image\",\n                contents=[\n                MediaContent(type=\"media\", urls=[url,output_url])\n                ]\n                )\n            )\n            \n            content_blocks.append(\n                ContentBlock(\n                    title=\"Inference result\",\n                    contents=[\n                    TextContent(type=\"text\", text=infer_result)\n                    ]\n                )\n            )\n\n        message = Message(\n            text=\"This is the Yolov8  result\",\n            sender=\"User\",\n            sender_name=\"Qualcomm AI\",\n            content_blocks=content_blocks\n        )\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Message object from ChatInput",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Use as a template to create your own component.",
            "icon": "code",
            "base_classes": [
              "Message"
            ],
            "display_name": "yolov8 det ",
            "documentation": "http://docs.langflow.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "message"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-N6ZzD"
        },
        "selected": false,
        "width": 320,
        "height": 340,
        "positionAbsolute": {
          "x": 1403.3913773034235,
          "y": -361.9688197278271
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-OnDDF",
        "type": "genericNode",
        "position": {
          "x": 1392.3472072380193,
          "y": -728.171702826356
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# from langflow.field_typing import Data\nfrom langflow.custom import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.schema.content_block import ContentBlock\nfrom langflow.schema.content_types import TextContent, MediaContent\nimport socket\nimport sys\nimport subprocess\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"http://docs.langflow.org/components/custom\"\n    icon = \"code\"\n    name = \"CustomComponent\"\n\n    inputs = [\n                MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The Message object from ChatInput\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n    \n    def get_host_ip(self):\n        host_name=socket.gethostname()\n        ip_addr=socket.gethostbyname(host_name)\n        return ip_addr  \n\n    def build_output(self) -> Message:\n\n\n\n\n        image_path_list=[]\n        \n        \n        for file in self.message.files:\n            image_path=str(file.path)\n            image_path_list.append(image_path)\n            \n        print(f'image_path_list: {image_path_list}')\n    \n        original_cwd = os.getcwd()\n        \n\n        # Extract the file name and directory\n        directory, filename = os.path.split(image_path)\n        name, ext = os.path.splitext(filename)\n        output_filename = f\"{name}_inceptionv3_output.png\"\n        \n        # Create new file name\n        output_image_path = os.path.join(directory, output_filename)\n\n\n\n        user_folder_path = os.environ['USERPROFILE']\n        ai_helper_sample_path = os.path.join(original_cwd, '..\\\\ai-engine-direct-helper\\\\samples\\\\')\n        os.chdir(ai_helper_sample_path)\n        sys.path.append(ai_helper_sample_path)\n        from python.inception_v3.inception_v3 import main as inception_v3_main\n        #image_path=None,mask_path=None,output_path=None\n        result=inception_v3_main(input=image_path_list[0])            \n        #result='Hello'\n        print(f'{result}')\n        result_list=[]\n        result_list.append(result)\n        sys.path.remove(ai_helper_sample_path)\n\n    \n        os.chdir(original_cwd)\n\n\n\n    \n        url_list=[]\n        for each_item in image_path_list:\n            directory, filename = os.path.split(each_item)\n            url_list.append(f'http://{self.get_host_ip()}:8979/api/v1/files/images/{self.graph.flow_id}/{filename}')\n\n\n\n        \n        print(f'url_list: {url_list}')\n        content_blocks=[]\n        \n        for url,infer_result in zip(url_list,result_list):\n            \n            content_blocks.append(\n                ContentBlock(\n                title=\"Input Image\",\n                contents=[\n                MediaContent(type=\"media\", urls=[url])\n                ]\n                )\n            )\n            \n            content_blocks.append(\n                ContentBlock(\n                    title=\"Inference result\",\n                    contents=[\n                    TextContent(type=\"text\", text=infer_result)\n                    ]\n                )\n            )\n\n        message = Message(\n            text=\"This is the Inception Inference  result\",\n            sender=\"User\",\n            sender_name=\"Qualcomm AI\",\n            content_blocks=content_blocks\n        )\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Message object from ChatInput",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Use as a template to create your own component.",
            "icon": "code",
            "base_classes": [
              "Message"
            ],
            "display_name": "InceptionV3",
            "documentation": "http://docs.langflow.org/components/custom",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "output",
                "display_name": "Output",
                "method": "build_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "message"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-OnDDF"
        },
        "selected": false,
        "width": 320,
        "height": 340,
        "positionAbsolute": {
          "x": 1392.3472072380193,
          "y": -728.171702826356
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-VQXeS",
        "type": "genericNode",
        "position": {
          "x": 1394.0481284245202,
          "y": 1249.9352783462095
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=['Qwen2.0-7B-SSD'],\n            value='Qwen2.0-7B-SSD',\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Qwen2.0-7B-SSD"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "Qwen2.0-7B-SSD",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "http://127.0.0.1:8910/v1",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": true,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput",
                "load_from_db": false
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false
          },
          "type": "OpenAIModel",
          "id": "OpenAIModel-VQXeS"
        },
        "selected": true,
        "width": 320,
        "height": 672,
        "positionAbsolute": {
          "x": 1394.0481284245202,
          "y": 1249.9352783462095
        },
        "dragging": false
      }
    ],
    "edges": [
      {
        "source": "OpenAIModel-qr1bp",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-qr1bp,name:text_output,output_types:[Message]}",
        "target": "ConditionalRouter-awkKa",
        "targetHandle": "{fieldName:input_text,id:ConditionalRouter-awkKa,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_text",
            "id": "ConditionalRouter-awkKa",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-qr1bp",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-qr1bp{dataType:OpenAIModel,id:OpenAIModel-qr1bp,name:text_output,output_types:[Message]}-ConditionalRouter-awkKa{fieldName:input_text,id:ConditionalRouter-awkKa,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "ConditionalRouter-awkKa",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:other_result,output_types:[Message]}",
        "target": "Pass-WCW5M",
        "targetHandle": "{fieldName:ignored_message,id:Pass-WCW5M,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "ignored_message",
            "id": "Pass-WCW5M",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-awkKa",
            "name": "other_result",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConditionalRouter-awkKa{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:other_result,output_types:[Message]}-Pass-WCW5M{fieldName:ignored_message,id:Pass-WCW5M,inputTypes:[Message],type:str}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ChatInput-KDKV4",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-KDKV4,name:message,output_types:[Message]}",
        "target": "Pass-WCW5M",
        "targetHandle": "{fieldName:input_message,id:Pass-WCW5M,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_message",
            "id": "Pass-WCW5M",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-KDKV4",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-KDKV4{dataType:ChatInput,id:ChatInput-KDKV4,name:message,output_types:[Message]}-Pass-WCW5M{fieldName:input_message,id:Pass-WCW5M,inputTypes:[Message],type:str}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "TextInput-qUoeY",
        "sourceHandle": "{dataType:TextInput,id:TextInput-qUoeY,name:text,output_types:[Message]}",
        "target": "CustomComponent-CuNHs",
        "targetHandle": "{fieldName:message,id:CustomComponent-CuNHs,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "CustomComponent-CuNHs",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-qUoeY",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-qUoeY{dataType:TextInput,id:TextInput-qUoeY,name:text,output_types:[Message]}-CustomComponent-CuNHs{fieldName:message,id:CustomComponent-CuNHs,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "ConditionalRouter-awkKa",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:semantic_segmentation_result,output_types:[Message]}",
        "target": "CustomComponent-CuNHs",
        "targetHandle": "{fieldName:input_value,id:CustomComponent-CuNHs,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent-CuNHs",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-awkKa",
            "name": "semantic_segmentation_result",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConditionalRouter-awkKa{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:semantic_segmentation_result,output_types:[Message]}-CustomComponent-CuNHs{fieldName:input_value,id:CustomComponent-CuNHs,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CustomComponent-CuNHs",
        "sourceHandle": "{dataType:CustomComponent,id:CustomComponent-CuNHs,name:output,output_types:[Message]}",
        "target": "ChatOutput-P24jk",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-P24jk,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-P24jk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-CuNHs",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-CuNHs{dataType:CustomComponent,id:CustomComponent-CuNHs,name:output,output_types:[Message]}-ChatOutput-P24jk{fieldName:input_value,id:ChatOutput-P24jk,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "ConditionalRouter-awkKa",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:pose_estimation_result,output_types:[Message]}",
        "target": "CustomComponent-tNBEY",
        "targetHandle": "{fieldName:input_value,id:CustomComponent-tNBEY,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent-tNBEY",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-awkKa",
            "name": "pose_estimation_result",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConditionalRouter-awkKa{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:pose_estimation_result,output_types:[Message]}-CustomComponent-tNBEY{fieldName:input_value,id:CustomComponent-tNBEY,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "TextInput-qUoeY",
        "sourceHandle": "{dataType:TextInput,id:TextInput-qUoeY,name:text,output_types:[Message]}",
        "target": "CustomComponent-tNBEY",
        "targetHandle": "{fieldName:message,id:CustomComponent-tNBEY,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "CustomComponent-tNBEY",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-qUoeY",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-qUoeY{dataType:TextInput,id:TextInput-qUoeY,name:text,output_types:[Message]}-CustomComponent-tNBEY{fieldName:message,id:CustomComponent-tNBEY,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CustomComponent-tNBEY",
        "sourceHandle": "{dataType:CustomComponent,id:CustomComponent-tNBEY,name:output,output_types:[Message]}",
        "target": "ChatOutput-qHo0x",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-qHo0x,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-qHo0x",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-tNBEY",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-tNBEY{dataType:CustomComponent,id:CustomComponent-tNBEY,name:output,output_types:[Message]}-ChatOutput-qHo0x{fieldName:input_value,id:ChatOutput-qHo0x,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "ConditionalRouter-awkKa",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:super_resolution_result,output_types:[Message]}",
        "target": "CustomComponent-bIZHN",
        "targetHandle": "{fieldName:input_value,id:CustomComponent-bIZHN,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent-bIZHN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-awkKa",
            "name": "super_resolution_result",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConditionalRouter-awkKa{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:super_resolution_result,output_types:[Message]}-CustomComponent-bIZHN{fieldName:input_value,id:CustomComponent-bIZHN,inputTypes:[Message],type:str}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "TextInput-qUoeY",
        "sourceHandle": "{dataType:TextInput,id:TextInput-qUoeY,name:text,output_types:[Message]}",
        "target": "CustomComponent-bIZHN",
        "targetHandle": "{fieldName:message,id:CustomComponent-bIZHN,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "CustomComponent-bIZHN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-qUoeY",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-qUoeY{dataType:TextInput,id:TextInput-qUoeY,name:text,output_types:[Message]}-CustomComponent-bIZHN{fieldName:message,id:CustomComponent-bIZHN,inputTypes:[Message],type:str}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "CustomComponent-bIZHN",
        "sourceHandle": "{dataType:CustomComponent,id:CustomComponent-bIZHN,name:output,output_types:[Message]}",
        "target": "ChatOutput-E9zvI",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-E9zvI,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-E9zvI",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-bIZHN",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-bIZHN{dataType:CustomComponent,id:CustomComponent-bIZHN,name:output,output_types:[Message]}-ChatOutput-E9zvI{fieldName:input_value,id:ChatOutput-E9zvI,inputTypes:[Message],type:str}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "TextInput-qUoeY",
        "sourceHandle": "{dataType:TextInput,id:TextInput-qUoeY,name:text,output_types:[Message]}",
        "target": "CustomComponent-N6ZzD",
        "targetHandle": "{fieldName:message,id:CustomComponent-N6ZzD,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "CustomComponent-N6ZzD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-qUoeY",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-qUoeY{dataType:TextInput,id:TextInput-qUoeY,name:text,output_types:[Message]}-CustomComponent-N6ZzD{fieldName:message,id:CustomComponent-N6ZzD,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CustomComponent-N6ZzD",
        "sourceHandle": "{dataType:CustomComponent,id:CustomComponent-N6ZzD,name:output,output_types:[Message]}",
        "target": "ChatOutput-HPvIk",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-HPvIk,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-HPvIk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-N6ZzD",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-N6ZzD{dataType:CustomComponent,id:CustomComponent-N6ZzD,name:output,output_types:[Message]}-ChatOutput-HPvIk{fieldName:input_value,id:ChatOutput-HPvIk,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "ConditionalRouter-awkKa",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:object_detection_result,output_types:[Message]}",
        "target": "CustomComponent-N6ZzD",
        "targetHandle": "{fieldName:input_value,id:CustomComponent-N6ZzD,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent-N6ZzD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-awkKa",
            "name": "object_detection_result",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConditionalRouter-awkKa{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:object_detection_result,output_types:[Message]}-CustomComponent-N6ZzD{fieldName:input_value,id:CustomComponent-N6ZzD,inputTypes:[Message],type:str}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CustomComponent-OnDDF",
        "sourceHandle": "{dataType:CustomComponent,id:CustomComponent-OnDDF,name:output,output_types:[Message]}",
        "target": "ChatOutput-RVEjl",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-RVEjl,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-RVEjl",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-OnDDF",
            "name": "output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-OnDDF{dataType:CustomComponent,id:CustomComponent-OnDDF,name:output,output_types:[Message]}-ChatOutput-RVEjl{fieldName:input_value,id:ChatOutput-RVEjl,inputTypes:[Message],type:str}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ConditionalRouter-awkKa",
        "sourceHandle": "{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:image_classification_result,output_types:[Message]}",
        "target": "CustomComponent-OnDDF",
        "targetHandle": "{fieldName:input_value,id:CustomComponent-OnDDF,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent-OnDDF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-awkKa",
            "name": "image_classification_result",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ConditionalRouter-awkKa{dataType:ConditionalRouter,id:ConditionalRouter-awkKa,name:image_classification_result,output_types:[Message]}-CustomComponent-OnDDF{fieldName:input_value,id:CustomComponent-OnDDF,inputTypes:[Message],type:str}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "Pass-WCW5M",
        "sourceHandle": "{dataType:Pass,id:Pass-WCW5M,name:output_message,output_types:[Message]}",
        "target": "OpenAIModel-VQXeS",
        "targetHandle": "{fieldName:input_value,id:OpenAIModel-VQXeS,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-VQXeS",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Pass",
            "id": "Pass-WCW5M",
            "name": "output_message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Pass-WCW5M{dataType:Pass,id:Pass-WCW5M,name:output_message,output_types:[Message]}-OpenAIModel-VQXeS{fieldName:input_value,id:OpenAIModel-VQXeS,inputTypes:[Message],type:str}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "OpenAIModel-VQXeS",
        "sourceHandle": "{dataType:OpenAIModel,id:OpenAIModel-VQXeS,name:text_output,output_types:[Message]}",
        "target": "ChatOutput-GePEK",
        "targetHandle": "{fieldName:input_value,id:ChatOutput-GePEK,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-GePEK",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-VQXeS",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-VQXeS{dataType:OpenAIModel,id:OpenAIModel-VQXeS,name:text_output,output_types:[Message]}-ChatOutput-GePEK{fieldName:input_value,id:ChatOutput-GePEK,inputTypes:[Message],type:str}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "Prompt-9opmi",
        "sourceHandle": "{dataType:Prompt,id:Prompt-9opmi,name:prompt,output_types:[Message]}",
        "target": "OpenAIModel-qr1bp",
        "targetHandle": "{fieldName:system_message,id:OpenAIModel-qr1bp,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-qr1bp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-9opmi",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-9opmi{dataType:Prompt,id:Prompt-9opmi,name:prompt,output_types:[Message]}-OpenAIModel-qr1bp{fieldName:system_message,id:OpenAIModel-qr1bp,inputTypes:[Message],type:str}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ChatInput-KDKV4",
        "sourceHandle": "{dataType:ChatInput,id:ChatInput-KDKV4,name:message,output_types:[Message]}",
        "target": "OpenAIModel-qr1bp",
        "targetHandle": "{fieldName:input_value,id:OpenAIModel-qr1bp,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-qr1bp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-KDKV4",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-KDKV4{dataType:ChatInput,id:ChatInput-KDKV4,name:message,output_types:[Message]}-OpenAIModel-qr1bp{fieldName:input_value,id:OpenAIModel-qr1bp,inputTypes:[Message],type:str}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "TextInput-qUoeY",
        "sourceHandle": "{dataType:TextInput,id:TextInput-qUoeY,name:text,output_types:[Message]}",
        "target": "CustomComponent-OnDDF",
        "targetHandle": "{fieldName:message,id:CustomComponent-OnDDF,inputTypes:[Message],type:str}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "CustomComponent-OnDDF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-qUoeY",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-TextInput-qUoeY{dataType:TextInput,id:TextInput-qUoeY,name:text,output_types:[Message]}-CustomComponent-OnDDF{fieldName:message,id:CustomComponent-OnDDF,inputTypes:[Message],type:str}",
        "animated": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": 518.9667863694152,
      "y": 244.0473103717503,
      "zoom": 0.37005456010810833
    }
  }
}