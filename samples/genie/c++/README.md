<br>

<div align="center">
  <h3>Run the large language model on the local NPU.</h3>
  <p><i> OpenAI Compatible API Service (C++) </i></p>
</div>
<br>

## Disclaimer

This software is provided “as is,” without any express or implied warranties. The authors and contributors shall not be
held liable for any damages arising from its use. The code may be incomplete or insufficiently tested. Users are solely
responsible for evaluating its suitability and assume all associated risks. <br>
Note: Contributions are welcome. Please ensure thorough testing before deploying in critical systems.

## Introduction

This sample helps developers use C++ to build Genie based Open AI compatibility API service on Windows on Snapdragon (
WoS), Mobile and Linux platforms.

## Features

• Support LLM on both CPU & NPU [*NEW!*] <br>
• Support both stream and none stream mode <br>
• Support switching between models <br>
• Support customization model <br>
• Support text splitter feature <br>
• Support tools call <br>
• Support enable/disable thinking mode <br>
• Support lora <br>
• Support history feature <br>

## GenieAPIService

Genie OpenAI Compatible API Service.

This is an OpenAI compatible API service that can be used to access the Genie AI model.
This service can be used on multiple platforms such as Android, Windows, Linux, etc.

## GenieAPIService API:

Refere to [API](docs/API.md) for detailed information.

## GenieService & Client usage:

It is located at [USAGE](docs/USAGE.md)

### More Sample Code

You can find more client sample code [here](../python/README.md#sample-list).

